# Quality Control of the raw datasets
# construct the environment and activate it

conda create -n rnaseq
conda activate rnaseq

# install FastQC 

conda install fastqc
conda install multiqc

# run fastqc

mkdir /home/shpc_100393/rna_seq/1.raw.data./2.raw.data.fastqc
nohup fastqc -t 18 -q -o 1.raw.data/2.raw.data.fastqc /1.raw.data/*.gz &

# merge the separate fastqc reports into one file using multiqc
multiqc /home/shpc_100393/rna_seq1.raw.data/2.raw.data.fastqc/* -o  /home/shpc_100393/rna_seq1.raw.data./2.raw.data.fastqc/

# remove the adaptor using cutadapt (data was generated by illumina)
# install cutadapt

conda install cutadapt 

# run cutadapt

mkdir /home/shpc_100393/rna_seq/2.trim.data

# since we have multipul files, we can iterate the conmmand using a shell script

vim cutadapt_batch.sh
#!/bin/bash
for id in DL_1  DL_2 DL_3 DN_1 DN_2 DN_3 M31_SL_C M31_UL_A M31_UL_B M31_UL_C M31_UL_D M31_UN_A M31_UN_B M31_UN_C M31_UN_D 
do 
    cutadapt -a AGATCGGAAGAGC -A AGATCGGAAGAGC -j 9 -e 0.1 -m 20 -q 10 
    -o /3.trim.data/${id}.trimmed_1_fastq.gz\
    -p /3.trim.data/${id}.trimmed_2_fastq.gz\
    /1.raw.data/${id}_1.fastq.gz /1.raw.data/${id}_2.fastq.gz 
    echo "this is sample ${id} step"
    done
    
nohup ./cutadapt_batch.sh &

# Afther this step has been done, we can rerun fastqc to check the adaptor trimming results


# Using Salmon to perform quantification using selective-aginment in mapping-based model 

mkdir /home/shpc_100393/rna_seq/3.salmon
cd /home/shpc_100393/rna_seq/3.salmon
wget https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh

# install mashmap
conda install -c bioconda mashmap bedtools 
conda -c install gsl
conda install libcxx
conda install zlib

# download the gtf annotation file 
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.annotation.gtf.gz
gunzip gencode.vM28.annotation.gtf

# download the reference genome
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/GRCm39.primary_assembly.genome.fa.gz
gunzip GRCm39.primary_assembly.genome.fa.gz

# download the transcrips file
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.transcripts.fa.gz
gunzip gencode.vM28.transcripts.fa.gz


#get the available path of bedrools and mashmap respectively
which bedtools
which mashmap

# get the decoy file
bash generateDecoyTranscriptome.sh -j 12 -b /bedtools/path -m /mashmap/path \
  -a gencode.vM28.annotation.gtf.gz \
  -g GRCm39.primary_assembly.genome.fa.gz \
  -t gencode.vM28.transcripts.fa.gz \
  -o decoy_file


# constrcuct the index
salmon index -t gencode.vM28.transcripts.fa.gz --decoys decoy_file/decoys.txt -p 16 -i salmon_index_particial_decoy -k 31 --gencode

#quantifying the batches of sample

mkdir /home/shpc_100393/rna_seq/4.quant
#!/bin/bash
for id in ...

do
echo "Processing sample ${id}"
salmon quant -i salmon_index_particial_decoy -l A \
         -1 /home/shpc_100393/rna_seq/1.raw.data/${id}_1.fastq.gz \
         -2 /home/shpc_100393/rna_seq/1.raw.data/${id}_2.fastq.gz \
         -p 16 --validateMappings -o /home/shpc_100393/rna_seq/4.quant/${id}_quant
         
done 

# merge all the transcripts level into one file
mkdir /home/shpc_100393/rna_seq/4.quant/4.quant.merge
cd /home/shpc_100393/rna_seq/4.quant/4.quant.merge

salmon quantmerge \
--quants {...} \
--names {...} \ 
--coloum=tpm  \
-o /home/shpc_100393/rna_seq/4.quant/4.quant.merge/merge_tpm.txt

library(DESeq2)
library("tximport")
library("readr")
tx2gene <- read_csv("trans2gene.csv")
samples <- data.frame(run = c('T11', 'T12', 'T13', 'T21', 'T22', 'T23'), condition = c("T1","T1","T1","T2","T2","T2"))
files <- file.path('.', paste(substring(samples$run, 1,3),".sf", sep = "")) # set salmon result files, each sample names plus '.sf'
names(files) <- samples$run
txi <- tximport(files, type="salmon", tx2gene=tx2gene)
head(txi$counts)
dds <- DESeqDataSetFromTximport(txi, colData=samples, design= ~ condition)
dds <- DESeq(dds)
res <- results(dds)
write.table(res,"T1_2.csv", sep = ",", row.names = TRUE)












