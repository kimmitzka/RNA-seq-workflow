# Quality Control of the raw datasets
# construct the environment and activate it

conda create -n rnaseq
conda activate rnaseq

# install FastQC 

conda install fastqc
conda install multiqc

# run fastqc

mkdir /home/shpc_100393/rna_seq/1.raw.data./2.raw.data.fastqc
nohup fastqc -t 18 -q -o 1.raw.data/2.raw.data.fastqc /1.raw.data/*.gz &

# merge the separate fastqc reports into one file using multiqc
multiqc /home/shpc_100393/rna_seq1.raw.data/2.raw.data.fastqc/* -o  /home/shpc_100393/rna_seq1.raw.data./2.raw.data.fastqc/

# remove the adaptor using cutadapt (data was generated by illumina)
# install cutadapt

conda install cutadapt 

# run cutadapt

mkdir /home/shpc_100393/rna_seq/2.trim.data

# since we have multipul files, we can iterate the conmmand using a shell script

vim cutadapt_batch.sh
#!/bin/bash
for id in MON1 MON2 MON3 MOL1 MOL2 MOL4 M31UNA M31UNB M31UNC M31UND M31ULA M31ULB M31ULC M31ULD M31SLC DN1 DN2 DN3 DL1 DL2 DL3
do
        cutadapt -a AGATCGAAGAGC -A AGATCGGAAGAGC -j 9 -e 0.1 -m 20 -q 10 \
                -o ../2.trim.data/${id}.trimmed_1_fastq.gz \
                -p ../2.trim.data/${id}.trimmed_2_fastq.gz ./${id}_1.fastq.gz ./${id}_2.fastq.gz
                echo "this is sample ${id} step"
        done

chmod +x ./cut.sh
nohup ./cut.sh &

# Afther this step has been done, we can rerun fastqc to check the adaptor trimming results


# Using Salmon to perform quantification using selective-aginment in mapping-based model 

mkdir /home/shpc_100393/rna_seq/3.salmon
cd /home/shpc_100393/rna_seq/3.salmon
wget https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh

# install mashmap
conda install -c bioconda mashmap bedtools 
conda -c install gsl
conda install libcxx
conda install zlib

# download the gtf annotation file 
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.annotation.gtf.gz
gunzip gencode.vM28.annotation.gtf

# download the reference genome
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/GRCm39.primary_assembly.genome.fa.gz
gunzip GRCm39.primary_assembly.genome.fa.gz

# download the transcrips file
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.transcripts.fa.gz
gunzip gencode.vM28.transcripts.fa.gz


#get the available path of bedrools and mashmap respectively
which bedtools
which mashmap

# get the decoy file 

bash generateDecoyTranscriptome.sh \
    -j 12 \
    -b /home/shpc_100393/miniconda3/bin/bedtools \
    -m /home/shpc_100393/miniconda3/bin/mashmap \
    -a gencode.vM28.annotation.gtf \
    -g GRCm39.primary_assembly.genome.fa \
    -t gencode.vM28.transcripts.fa \
    -o decoy_file


# constrcuct the index (using a version=1.0.0 salmon here)
/home/shpc_100393/rna_seq/3.salmon/version/salmon-latest_linux_x86_64/bin/salmon index \ 
-t gencode.vM28.transcripts.fa \
--decoys decoy_file/decoys.txt \
-p 16 -i salmon_index_particial_decoy \
-k 31 --gencode


#quantifying the batches of sample

mkdir /home/shpc_100393/rna_seq/4.quant

#!/bin/bash
for id in DL1 DL2

do
echo "Processing sample ${id}"
../3.salmon/version/salmon-latest_linux_x86_64/bin/salmon quant -i ../3.salmon/salmon_index_particial_decoy -l A \
         -1 ./${id}.trimmed_1_fastq.gz \
         -2 ./${id}.trimmed_2_fastq.gz \
         -p 16 --validateMappings -o ../4.quant/${id}_quant
         
done 

chmod +x ./quant.sh
# merge all the transcripts level into one file
mkdir /home/shpc_100393/rna_seq/4.quant/4.quant.merge
cd /home/shpc_100393/rna_seq/4.quant/4.quant.merge

salmon quantmerge \
--quants {...} \
--names {...} \ 
--coloum=tpm  \
-o /home/shpc_100393/rna_seq/4.quant/4.quant.merge/merge_tpm.txt












